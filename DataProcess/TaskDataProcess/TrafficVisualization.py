import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False


class TrafficAnalyzer:
    def __init__(self, file_path):
        """åˆå§‹åŒ–äº¤é€šæµé‡åˆ†æå™¨"""
        self.file_path = file_path
        self.df = None
        self.load_data()

    def load_data(self):
        """åŠ è½½æ•°æ®"""
        try:
            self.df = pd.read_csv(self.file_path, encoding='utf-8')
            print(f"æ•°æ®åŠ è½½æˆåŠŸï¼æ•°æ®å½¢çŠ¶: {self.df.shape}")
            print(f"åˆ—å: {list(self.df.columns)}")
        except UnicodeDecodeError:
            # å°è¯•å…¶ä»–ç¼–ç 
            try:
                self.df = pd.read_csv(self.file_path, encoding='gbk')
                print(f"æ•°æ®åŠ è½½æˆåŠŸï¼ˆGBKç¼–ç ï¼‰ï¼æ•°æ®å½¢çŠ¶: {self.df.shape}")
            except:
                print("æ•°æ®åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„å’Œç¼–ç ")
                return None
        except Exception as e:
            print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return None

    def basic_info(self):
        """åŸºç¡€æ•°æ®ä¿¡æ¯"""
        print("\n" + "=" * 50)
        print("åŸºç¡€æ•°æ®ä¿¡æ¯")
        print("=" * 50)

        print(f"æ•°æ®é›†å¤§å°: {self.df.shape[0]} è¡Œ, {self.df.shape[1]} åˆ—")
        print(f"æ•°æ®ç±»å‹:")
        print(self.df.dtypes)

        print(f"\nç¼ºå¤±å€¼ç»Ÿè®¡:")
        missing_data = self.df.isnull().sum()
        print(missing_data[missing_data > 0] if missing_data.sum() > 0 else "æ— ç¼ºå¤±å€¼")

        print(f"\nå‰5è¡Œæ•°æ®:")
        print(self.df.head())

        print(f"\nå5è¡Œæ•°æ®:")
        print(self.df.tail())

    def descriptive_statistics(self):
        """æè¿°æ€§ç»Ÿè®¡åˆ†æ"""
        print("\n" + "=" * 50)
        print("æè¿°æ€§ç»Ÿè®¡åˆ†æ")
        print("=" * 50)

        # åŸºç¡€ç»Ÿè®¡ä¿¡æ¯
        print("åŸºç¡€ç»Ÿè®¡ä¿¡æ¯:")
        print(self.df.describe())

        # å„è½¦å‹æµé‡ç»Ÿè®¡
        print(f"\nå„è½¦å‹æ€»æµé‡æ’å:")
        total_traffic = self.df.sum().sort_values(ascending=False)
        for i, (vehicle_type, total) in enumerate(total_traffic.items(), 1):
            percentage = (total / total_traffic.sum()) * 100
            print(f"{i}. {vehicle_type}: {total:,} è¾† ({percentage:.2f}%)")

        # å¹³å‡æµé‡ç»Ÿè®¡
        print(f"\nå„è½¦å‹å¹³å‡æµé‡:")
        avg_traffic = self.df.mean().sort_values(ascending=False)
        for vehicle_type, avg in avg_traffic.items():
            print(f"{vehicle_type}: {avg:.0f} è¾†")

    def time_series_analysis(self):
        """æ—¶é—´åºåˆ—åˆ†æ"""
        print("\n" + "=" * 50)
        print("æ—¶é—´åºåˆ—åˆ†æ")
        print("=" * 50)

        # æ·»åŠ æ—¶é—´ç´¢å¼•ï¼ˆå‡è®¾æ•°æ®æŒ‰æ—¶é—´é¡ºåºæ’åˆ—ï¼‰
        self.df['æ—¶é—´ç‚¹'] = range(1, len(self.df) + 1)

        # æ€»æµé‡å˜åŒ–
        if 'è½¦æµé‡' in self.df.columns:
            total_col = 'è½¦æµé‡'
        else:
            # å¦‚æœæ²¡æœ‰æ€»æµé‡åˆ—ï¼Œè®¡ç®—æ€»å’Œ
            numeric_cols = self.df.select_dtypes(include=[np.number]).columns
            if 'æ—¶é—´ç‚¹' in numeric_cols:
                numeric_cols = numeric_cols.drop('æ—¶é—´ç‚¹')
            self.df['æ€»æµé‡'] = self.df[numeric_cols].sum(axis=1)
            total_col = 'æ€»æµé‡'

        print(f"æ€»æµé‡ç»Ÿè®¡:")
        print(f"æœ€é«˜æµé‡: {self.df[total_col].max():,} è¾† (ç¬¬{self.df[total_col].idxmax() + 1}ä¸ªæ—¶é—´ç‚¹)")
        print(f"æœ€ä½æµé‡: {self.df[total_col].min():,} è¾† (ç¬¬{self.df[total_col].idxmin() + 1}ä¸ªæ—¶é—´ç‚¹)")
        print(f"æµé‡å˜åŒ–å¹…åº¦: {self.df[total_col].max() - self.df[total_col].min():,} è¾†")

        # è®¡ç®—å˜åŒ–ç‡
        self.df['æµé‡å˜åŒ–ç‡'] = self.df[total_col].pct_change() * 100
        print(f"\næœ€å¤§å¢é•¿ç‡: {self.df['æµé‡å˜åŒ–ç‡'].max():.2f}%")
        print(f"æœ€å¤§ä¸‹é™ç‡: {self.df['æµé‡å˜åŒ–ç‡'].min():.2f}%")

    def correlation_analysis(self):
        """ç›¸å…³æ€§åˆ†æ"""
        print("\n" + "=" * 50)
        print("è½¦å‹é—´ç›¸å…³æ€§åˆ†æ")
        print("=" * 50)

        # é€‰æ‹©æ•°å€¼åˆ—è¿›è¡Œç›¸å…³æ€§åˆ†æ
        numeric_cols = self.df.select_dtypes(include=[np.number]).columns
        if 'æ—¶é—´ç‚¹' in numeric_cols:
            numeric_cols = numeric_cols.drop('æ—¶é—´ç‚¹')
        if 'æµé‡å˜åŒ–ç‡' in numeric_cols:
            numeric_cols = numeric_cols.drop('æµé‡å˜åŒ–ç‡')

        correlation_matrix = self.df[numeric_cols].corr()
        print("ç›¸å…³ç³»æ•°çŸ©é˜µ:")
        print(correlation_matrix.round(3))

        # æ‰¾å‡ºé«˜ç›¸å…³æ€§çš„è½¦å‹å¯¹
        print(f"\né«˜ç›¸å…³æ€§è½¦å‹å¯¹ (|r| > 0.8):")
        for i in range(len(correlation_matrix.columns)):
            for j in range(i + 1, len(correlation_matrix.columns)):
                corr_val = correlation_matrix.iloc[i, j]
                if abs(corr_val) > 0.8:
                    print(f"{correlation_matrix.columns[i]} - {correlation_matrix.columns[j]}: {corr_val:.3f}")

    def anomaly_detection(self):
        """å¼‚å¸¸å€¼æ£€æµ‹"""
        print("\n" + "=" * 50)
        print("å¼‚å¸¸å€¼æ£€æµ‹")
        print("=" * 50)

        numeric_cols = self.df.select_dtypes(include=[np.number]).columns
        if 'æ—¶é—´ç‚¹' in numeric_cols:
            numeric_cols = numeric_cols.drop('æ—¶é—´ç‚¹')
        if 'æµé‡å˜åŒ–ç‡' in numeric_cols:
            numeric_cols = numeric_cols.drop('æµé‡å˜åŒ–ç‡')

        for col in numeric_cols:
            Q1 = self.df[col].quantile(0.25)
            Q3 = self.df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR

            outliers = self.df[(self.df[col] < lower_bound) | (self.df[col] > upper_bound)]
            if not outliers.empty:
                print(f"\n{col} å¼‚å¸¸å€¼:")
                for idx, row in outliers.iterrows():
                    print(f"  æ—¶é—´ç‚¹ {idx + 1}: {row[col]:,} è¾†")
            else:
                print(f"\n{col}: æ— å¼‚å¸¸å€¼")

    def create_visualizations(self):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        print("\n" + "=" * 50)
        print("ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        print("=" * 50)

        # è®¾ç½®å›¾è¡¨æ ·å¼
        plt.style.use('seaborn-v0_8')
        fig = plt.figure(figsize=(20, 15))

        # è·å–æ•°å€¼åˆ—
        numeric_cols = self.df.select_dtypes(include=[np.number]).columns
        if 'æ—¶é—´ç‚¹' in numeric_cols:
            numeric_cols = numeric_cols.drop('æ—¶é—´ç‚¹')
        if 'æµé‡å˜åŒ–ç‡' in numeric_cols:
            plot_cols = numeric_cols.drop('æµé‡å˜åŒ–ç‡')
        else:
            plot_cols = numeric_cols

        # 1. æ—¶é—´åºåˆ—å›¾
        plt.subplot(3, 3, 1)
        for col in plot_cols:
            plt.plot(self.df['æ—¶é—´ç‚¹'], self.df[col], marker='o', label=col, linewidth=2)
        plt.title('å„è½¦å‹æµé‡æ—¶é—´åºåˆ—', fontsize=14, fontweight='bold')
        plt.xlabel('æ—¶é—´ç‚¹')
        plt.ylabel('æµé‡ (è¾†)')
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        plt.grid(True, alpha=0.3)

        # 2. æ€»æµé‡é¥¼å›¾
        plt.subplot(3, 3, 2)
        total_by_type = self.df[plot_cols].sum()
        colors = plt.cm.Set3(np.linspace(0, 1, len(total_by_type)))
        wedges, texts, autotexts = plt.pie(total_by_type.values, labels=total_by_type.index,
                                           autopct='%1.1f%%', colors=colors, startangle=90)
        plt.title('å„è½¦å‹æ€»æµé‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')

        # 3. ç®±çº¿å›¾
        plt.subplot(3, 3, 3)
        self.df[plot_cols].boxplot(ax=plt.gca())
        plt.title('å„è½¦å‹æµé‡åˆ†å¸ƒç®±çº¿å›¾', fontsize=14, fontweight='bold')
        plt.xticks(rotation=45)
        plt.ylabel('æµé‡ (è¾†)')

        # 4. ç›¸å…³æ€§çƒ­åŠ›å›¾
        plt.subplot(3, 3, 4)
        correlation_matrix = self.df[plot_cols].corr()
        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
                    square=True, cbar_kws={'shrink': 0.8})
        plt.title('è½¦å‹é—´ç›¸å…³æ€§çƒ­åŠ›å›¾', fontsize=14, fontweight='bold')

        # 5. æŸ±çŠ¶å›¾ - å¹³å‡æµé‡
        plt.subplot(3, 3, 5)
        avg_traffic = self.df[plot_cols].mean().sort_values(ascending=False)
        bars = plt.bar(range(len(avg_traffic)), avg_traffic.values,
                       color=plt.cm.viridis(np.linspace(0, 1, len(avg_traffic))))
        plt.title('å„è½¦å‹å¹³å‡æµé‡', fontsize=14, fontweight='bold')
        plt.xticks(range(len(avg_traffic)), avg_traffic.index, rotation=45)
        plt.ylabel('å¹³å‡æµé‡ (è¾†)')

        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars:
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width() / 2., height,
                     f'{int(height)}', ha='center', va='bottom')

        # 6. æµé‡å˜åŒ–è¶‹åŠ¿
        if 'æµé‡å˜åŒ–ç‡' in self.df.columns:
            plt.subplot(3, 3, 6)
            plt.plot(self.df['æ—¶é—´ç‚¹'][1:], self.df['æµé‡å˜åŒ–ç‡'][1:],
                     marker='o', color='red', linewidth=2)
            plt.title('æ€»æµé‡å˜åŒ–ç‡è¶‹åŠ¿', fontsize=14, fontweight='bold')
            plt.xlabel('æ—¶é—´ç‚¹')
            plt.ylabel('å˜åŒ–ç‡ (%)')
            plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)
            plt.grid(True, alpha=0.3)

        # 7. ç´¯ç§¯æµé‡å›¾
        plt.subplot(3, 3, 7)
        cumulative = self.df[plot_cols].cumsum()
        for col in plot_cols:
            plt.plot(self.df['æ—¶é—´ç‚¹'], cumulative[col], marker='o', label=col, linewidth=2)
        plt.title('å„è½¦å‹ç´¯ç§¯æµé‡', fontsize=14, fontweight='bold')
        plt.xlabel('æ—¶é—´ç‚¹')
        plt.ylabel('ç´¯ç§¯æµé‡ (è¾†)')
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        plt.grid(True, alpha=0.3)

        # 8. æµé‡åˆ†å¸ƒç›´æ–¹å›¾ï¼ˆé€‰æ‹©æµé‡æœ€å¤§çš„è½¦å‹ï¼‰
        plt.subplot(3, 3, 8)
        max_traffic_col = self.df[plot_cols].sum().idxmax()
        plt.hist(self.df[max_traffic_col], bins=min(10, len(self.df)),
                 alpha=0.7, color='skyblue', edgecolor='black')
        plt.title(f'{max_traffic_col}æµé‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        plt.xlabel('æµé‡ (è¾†)')
        plt.ylabel('é¢‘æ¬¡')
        plt.grid(True, alpha=0.3)

        # 9. æµé‡å æ¯”å †ç§¯å›¾
        plt.subplot(3, 3, 9)
        percentages = self.df[plot_cols].div(self.df[plot_cols].sum(axis=1), axis=0) * 100
        bottom = np.zeros(len(self.df))
        colors = plt.cm.Set3(np.linspace(0, 1, len(plot_cols)))

        for i, col in enumerate(plot_cols):
            plt.bar(self.df['æ—¶é—´ç‚¹'], percentages[col], bottom=bottom,
                    label=col, color=colors[i])
            bottom += percentages[col]

        plt.title('å„æ—¶é—´ç‚¹è½¦å‹æµé‡å æ¯”', fontsize=14, fontweight='bold')
        plt.xlabel('æ—¶é—´ç‚¹')
        plt.ylabel('å æ¯” (%)')
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')

        plt.tight_layout()
        plt.show()

    def generate_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("äº¤é€šæµé‡æ•°æ®åˆ†ææŠ¥å‘Š")
        print("=" * 60)

        numeric_cols = self.df.select_dtypes(include=[np.number]).columns
        if 'æ—¶é—´ç‚¹' in numeric_cols:
            numeric_cols = numeric_cols.drop('æ—¶é—´ç‚¹')
        if 'æµé‡å˜åŒ–ç‡' in numeric_cols:
            plot_cols = numeric_cols.drop('æµé‡å˜åŒ–ç‡')
        else:
            plot_cols = numeric_cols

        # æ•°æ®æ¦‚è¿°
        print(f"\nğŸ“Š æ•°æ®æ¦‚è¿°:")
        print(f"â€¢ è§‚æµ‹æ—¶é—´ç‚¹: {len(self.df)} ä¸ª")
        print(f"â€¢ è½¦å‹ç§ç±»: {len(plot_cols)} ç§")
        print(f"â€¢ æ€»è§‚æµ‹æµé‡: {self.df[plot_cols].sum().sum():,} è¾†")

        # ä¸»è¦å‘ç°
        print(f"\nğŸ” ä¸»è¦å‘ç°:")

        # æœ€é«˜æµé‡è½¦å‹
        total_by_type = self.df[plot_cols].sum().sort_values(ascending=False)
        top_vehicle = total_by_type.index[0]
        print(
            f"â€¢ æµé‡æœ€å¤§è½¦å‹: {top_vehicle} ({total_by_type.iloc[0]:,} è¾†, å æ¯” {total_by_type.iloc[0] / total_by_type.sum() * 100:.1f}%)")

        # æœ€ä½æµé‡è½¦å‹
        bottom_vehicle = total_by_type.index[-1]
        print(
            f"â€¢ æµé‡æœ€å°è½¦å‹: {bottom_vehicle} ({total_by_type.iloc[-1]:,} è¾†, å æ¯” {total_by_type.iloc[-1] / total_by_type.sum() * 100:.1f}%)")

        # æµé‡æ³¢åŠ¨
        if 'è½¦æµé‡' in self.df.columns:
            total_col = 'è½¦æµé‡'
        else:
            total_col = 'æ€»æµé‡'

        if total_col in self.df.columns:
            max_traffic_time = self.df[total_col].idxmax() + 1
            min_traffic_time = self.df[total_col].idxmin() + 1
            print(f"â€¢ æµé‡é«˜å³°: ç¬¬{max_traffic_time}ä¸ªæ—¶é—´ç‚¹ ({self.df[total_col].max():,} è¾†)")
            print(f"â€¢ æµé‡ä½è°·: ç¬¬{min_traffic_time}ä¸ªæ—¶é—´ç‚¹ ({self.df[total_col].min():,} è¾†)")

        # ç›¸å…³æ€§åˆ†æç»“æœ
        correlation_matrix = self.df[plot_cols].corr()
        high_corr_pairs = []
        for i in range(len(correlation_matrix.columns)):
            for j in range(i + 1, len(correlation_matrix.columns)):
                corr_val = correlation_matrix.iloc[i, j]
                if abs(corr_val) > 0.8:
                    high_corr_pairs.append((correlation_matrix.columns[i],
                                            correlation_matrix.columns[j], corr_val))

        if high_corr_pairs:
            print(f"â€¢ é«˜ç›¸å…³æ€§è½¦å‹: {len(high_corr_pairs)} å¯¹è½¦å‹æµé‡é«˜åº¦ç›¸å…³")
        else:
            print(f"â€¢ è½¦å‹é—´ç›¸å…³æ€§: å„è½¦å‹æµé‡ç›¸å¯¹ç‹¬ç«‹")

        print(f"\nğŸ’¡ å»ºè®®:")
        print(f"â€¢ é‡ç‚¹å…³æ³¨ {top_vehicle}ï¼Œå…¶æµé‡å æ€»æµé‡çš„ {total_by_type.iloc[0] / total_by_type.sum() * 100:.1f}%")
        print(f"â€¢ åˆ†ææµé‡é«˜å³°å’Œä½è°·çš„æ—¶é—´è§„å¾‹ï¼Œä¼˜åŒ–äº¤é€šç®¡ç†")
        print(f"â€¢ æ ¹æ®è½¦å‹ç‰¹ç‚¹åˆ¶å®šå·®å¼‚åŒ–çš„äº¤é€šç­–ç•¥")

        # ä¿å­˜åˆ†æç»“æœåˆ°æ–‡ä»¶
        output_path = self.file_path.replace('.csv', '_analysis_report.txt')
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("äº¤é€šæµé‡æ•°æ®åˆ†ææŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"åˆ†ææ—¶é—´: {pd.Timestamp.now()}\n")
            f.write(f"æ•°æ®æ–‡ä»¶: {self.file_path}\n\n")
            f.write("æè¿°æ€§ç»Ÿè®¡:\n")
            f.write(str(self.df[plot_cols].describe()))
            f.write("\n\nç›¸å…³ç³»æ•°çŸ©é˜µ:\n")
            f.write(str(correlation_matrix.round(3)))

        print(f"\nğŸ“„ è¯¦ç»†åˆ†ææŠ¥å‘Šå·²ä¿å­˜è‡³: {output_path}")

    def run_complete_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        if self.df is None:
            print("æ•°æ®æœªæ­£ç¡®åŠ è½½ï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
            return

        print("å¼€å§‹äº¤é€šæµé‡æ•°æ®åˆ†æ...")

        # æ‰§è¡Œå„ç§åˆ†æ
        self.basic_info()
        self.descriptive_statistics()
        self.time_series_analysis()
        self.correlation_analysis()
        self.anomaly_detection()
        self.create_visualizations()
        self.generate_report()

        print("\nâœ… åˆ†æå®Œæˆï¼")


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æ›¿æ¢ä¸ºæ‚¨çš„æ–‡ä»¶è·¯å¾„
    file_path = r"D:\py\IRPP\DataProcess\ProcessData\Traffic_processed.csv"

    # åˆ›å»ºåˆ†æå™¨å®ä¾‹å¹¶è¿è¡Œåˆ†æ
    analyzer = TrafficAnalyzer(file_path)
    analyzer.run_complete_analysis()
